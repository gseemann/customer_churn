{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:57:14.110401Z",
     "start_time": "2021-01-02T00:57:14.104332Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:07.386524Z",
     "start_time": "2021-01-02T00:49:07.353551Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('customer_data.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get general understanding of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:08.510236Z",
     "start_time": "2021-01-02T00:49:08.506745Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:09.325824Z",
     "start_time": "2021-01-02T00:49:09.318009Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:09.980889Z",
     "start_time": "2021-01-02T00:49:09.929841Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for na and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:11.077071Z",
     "start_time": "2021-01-02T00:49:11.071533Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Value Counts on int rows\n",
    "- `International_planNo`, `International_planYes`, `Voice_mail_planNo` , `Voice_mail_planYes` are get dummies of `International_plan` and `Voice_mail_plan`\n",
    "- `Times_Mailed`,`No_of_tradelines` are continous only have 8 values and are therefore somewhat catagorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:11.733349Z",
     "start_time": "2021-01-02T00:49:11.710464Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='int64').columns:\n",
    "    print(col,'\\n', df[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:12.024881Z",
     "start_time": "2021-01-02T00:49:12.000805Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='float64').columns:\n",
    "    print(col,'\\n', df[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:12.268022Z",
     "start_time": "2021-01-02T00:49:12.259308Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(col,'\\n', df[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Let's graph int and catagorical like columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:14.171633Z",
     "start_time": "2021-01-02T00:49:12.800253Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "g=sns.countplot(x='State', hue=\"Churn_1\", data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Breakdown of states and churn')\n",
    "plt.savefig('figures/states_and_churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:49:27.417259Z",
     "start_time": "2021-01-02T00:49:14.191317Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='int64').columns:\n",
    "    plt.figure(figsize=(14,8))\n",
    "    g=sns.countplot(x=col, hue=\"Churn_1\", data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Breakdown of '+col+' against churn')\n",
    "    plt.savefig('figures/churn_'+col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:51:38.865348Z",
     "start_time": "2021-01-02T00:49:27.441240Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns_plot= sns.pairplot(df, hue='Churn_1')#, hue=\"species\", tit)\n",
    "sns_plot.savefig(\"figures/Churn_continous'\")\n",
    "# plt.title('Relationship between Continous Variables and Churn')\n",
    "# plt.savefig('figures/Churn_continous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hmmmm looks like amount charged may be related to Churn\n",
    "Let's make a total charge column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:51:38.897335Z",
     "start_time": "2021-01-02T00:51:38.892349Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['total_charge']=df.Total_day_charge+df.Total_eve_charge+df.Total_night_charge+df.Total_intl_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:51:38.931102Z",
     "start_time": "2021-01-02T00:51:38.920917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:07.855900Z",
     "start_time": "2021-01-02T00:51:38.953062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns_plot= sns.pairplot(df, hue='Churn_1')#, hue=\"species\", tit)\n",
    "# sns_plot.savefig(\"figures/Churn_continous'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- There seems to be some correlation between high total_charge and Churn\n",
    "- Perhaps a coupon/discount could mitigate Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:08.590852Z",
     "start_time": "2021-01-02T00:54:07.881481Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(data=df,x='total_charge',kde=True, kind='hist', hue='Churn_1', height=8)\n",
    "plt.title(\"Total Charge and Churn\")\n",
    "plt.savefig(\"figures/total_charge_churn\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:08.975037Z",
     "start_time": "2021-01-02T00:54:08.614433Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "g=sns.countplot(x='Customer_service_calls', hue=\"Churn_1\", data=df)\n",
    "plt.title(\"Customer service calls and Churn\")\n",
    "plt.savefig(\"figures/customer_calls_churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and testing\n",
    "- we will try to predict `Churn_1`\n",
    "- we need to address the imbalence in `Churn_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:08.999037Z",
     "start_time": "2021-01-02T00:54:08.996164Z"
    }
   },
   "outputs": [],
   "source": [
    "predictors =['State','Account_length', 'Area_code', \n",
    "        'Number_vmail_messages', 'Total_day_minutes',\n",
    "       'Total_day_calls', 'Total_day_charge', 'Total_eve_minutes',\n",
    "       'Total_eve_calls', 'Total_eve_charge', 'Total_night_minutes',\n",
    "       'Total_night_calls', 'Total_night_charge', 'Total_intl_minutes',\n",
    "       'Total_intl_calls', 'Total_intl_charge', 'Customer_service_calls',\n",
    "        'International_planYes', 'Voice_mail_planYes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.029162Z",
     "start_time": "2021-01-02T00:54:09.022584Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Churn_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get dummies for catagorical predictors \n",
    " - `International_planNo/YES`, `Voice_mail_planYes/NO` <- already in binary format\n",
    " - `State` are str(object) time -> getdummies can be used\n",
    " - well also convert `Area_code` to str so its captured by get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.056670Z",
     "start_time": "2021-01-02T00:54:09.053536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Area_code= df.Area_code.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Assign y and X then break into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.097641Z",
     "start_time": "2021-01-02T00:54:09.081532Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df[[\"Churn_1\"]]\n",
    "X = pd.get_dummies(df.loc[:,predictors])\n",
    "\n",
    "# Perform test train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.179094Z",
     "start_time": "2021-01-02T00:54:09.173034Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.254541Z",
     "start_time": "2021-01-02T00:54:09.247226Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Start by Over-sampling Churn_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.330243Z",
     "start_time": "2021-01-02T00:54:09.325172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.415658Z",
     "start_time": "2021-01-02T00:54:09.412207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df_train.Churn_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.493962Z",
     "start_time": "2021-01-02T00:54:09.489570Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train.Churn_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.579456Z",
     "start_time": "2021-01-02T00:54:09.574172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_class_0 = df_train[df_train['Churn_1'] == 0]\n",
    "df_class_1 = df_train[df_train['Churn_1'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:09.696769Z",
     "start_time": "2021-01-02T00:54:09.688620Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#oversampling\n",
    "df_class_1_over = df_class_1.sample(n=count_class_0,replace=True)\n",
    "df_test_under = pd.concat([df_class_1_over, df_class_0], axis=0)\n",
    "\n",
    "#balenced y_train and X_train\n",
    "y_train = df_test_under['Churn_1']\n",
    "X_train = df_test_under.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:54:10.953003Z",
     "start_time": "2021-01-02T00:54:10.947825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:00:33.251290Z",
     "start_time": "2021-01-01T23:00:29.278321Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logreg = LogisticRegressionCV(Cs=5,max_iter=1000000, cv=3, penalty='l2', scoring='accuracy', verbose=1,\n",
    "#                              solver='lbfgs',random_state=12)\n",
    "logreg = LogisticRegression(C=.1, max_iter=10000, penalty='elasticnet', verbose=1,\n",
    "                             solver='saga',random_state=12,l1_ratio=.9, n_jobs=-1)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:03:47.805392Z",
     "start_time": "2021-01-01T23:03:47.802101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_parameters = logreg.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T19:54:47.170459Z",
     "start_time": "2020-12-29T19:54:47.164859Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dictionary = dict(zip(list(X_train.columns), list(logreg.coef_[0])))\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:03:51.460846Z",
     "start_time": "2021-01-01T23:03:51.449913Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_class = logreg.predict(X_test)\n",
    "y_pred_train = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:03:53.815599Z",
     "start_time": "2021-01-01T23:03:53.799378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy= metrics.accuracy_score(y_test, y_pred_class)\n",
    "recall= metrics.recall_score(y_test, y_pred_class)\n",
    "precision= metrics.precision_score(y_test, y_pred_class)\n",
    "f1= metrics.f1_score(y_test, y_pred_class)\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "fpr = 1 - tnr\n",
    "\n",
    "t_accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "t_recall = metrics.recall_score(y_train, y_pred_train)\n",
    "t_precision=metrics.precision_score(y_train, y_pred_train)\n",
    "t_f1=metrics.f1_score(y_train, y_pred_train)\n",
    "t_tnr = metrics.recall_score(y_train, y_pred_train, pos_label = 0)\n",
    "t_fpr = 1 - t_tnr\n",
    "\n",
    "print('Positive likelihood ratio',recall/fpr)\n",
    "print('recall_score', recall)\n",
    "print('precision_score', precision)\n",
    "print('accuracy_score', accuracy)\n",
    "print('f1_score', f1)\n",
    "\n",
    "print('\\nTraining Data')\n",
    "print('Positive likelihood ratio',t_recall/t_fpr)\n",
    "print('recall_score', t_recall)\n",
    "print('precision_score', t_precision)\n",
    "print('accuracy_score', t_accuracy)\n",
    "print('f1_score', t_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:03:56.019554Z",
     "start_time": "2021-01-01T23:03:56.009912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(y_test, y_pred_class)\n",
    "print('recall_score', metrics.recall_score(y_test, y_pred_class))\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "print('tnr', tnr)\n",
    "fpr = 1 - tnr\n",
    "print('fpr', fpr)\n",
    "print('Positive likelihood ratio',recall/fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:04:04.779763Z",
     "start_time": "2021-01-01T23:04:04.757537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(data=[metrics.accuracy_score(y_test, y_pred_class), metrics.recall_score(y_test, y_pred_class),\n",
    "                   metrics.precision_score(y_test, y_pred_class), metrics.f1_score(y_test, y_pred_class)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'test_set'}),\n",
    "pd.DataFrame(data=[metrics.accuracy_score(y_train, y_pred_train), metrics.recall_score(y_train, y_pred_train),\n",
    "                   metrics.precision_score(y_train, y_pred_train), metrics.f1_score(y_train, y_pred_train)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'train_set'})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T19:12:23.751712Z",
     "start_time": "2020-12-29T19:12:23.558366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm=confusion_matrix(y_test, y_pred_class)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\n",
    "plt.savefig(\"figures/Confusion_Matrix_Logreg\")\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix Logistic Regression Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Efron's R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T17:57:16.847550Z",
     "start_time": "2020-12-29T17:57:16.842188Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def efron_rsquare(y, y_pred):\n",
    "    n = float(len(y))\n",
    "    t1 = np.sum(np.power(y - y_pred, 2.0))\n",
    "    t2 = np.sum(np.power((y - (np.sum(y) / n)), 2.0))\n",
    "    return 1.0 - (t1 / t2)\n",
    "efron_rsquare(np.ravel(y_train), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### McFadden’s  R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T17:57:17.693486Z",
     "start_time": "2020-12-29T17:57:17.681766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def full_log_likelihood(w, X, y):\n",
    "    score = np.dot(X, w).reshape(1, X.shape[0])\n",
    "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
    "\n",
    "def null_log_likelihood(w, X, y):\n",
    "    z = np.array([w if i == 0 else 0.0 for i, w in enumerate(w.reshape(1, X.shape[1])[0])]).reshape(X.shape[1], 1)\n",
    "    score = np.dot(X, z).reshape(1, X.shape[0])\n",
    "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
    "\n",
    "def mcfadden_rsquare(w, X, y):\n",
    "    return 1.0 - (full_log_likelihood(w, X, y) / null_log_likelihood(w, X, y))\n",
    "\n",
    "def mcfadden_adjusted_rsquare(w, X, y):\n",
    "    k = float(X.shape[1])\n",
    "    return 1.0 - ((full_log_likelihood(w, X, y) - k) / null_log_likelihood(w, X, y))\n",
    "\n",
    "#get score\n",
    "mcfadden_rsquare(w, X_train, np.ravel(y_train))\n",
    "# mcfadden_rsquare(w, X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T16:17:01.890555Z",
     "start_time": "2020-12-28T16:17:01.885974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:45:27.275972Z",
     "start_time": "2020-12-28T17:45:27.105410Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(logreg, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:11.138438Z",
     "start_time": "2021-01-03T19:25:10.200268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_for = RandomForestClassifier(n_estimators=400, criterion='gini', max_depth=4, min_samples_split=.0001,\n",
    "        min_samples_leaf=1,min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "        min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=True, n_jobs=-1, \n",
    "        random_state=22, verbose=2,warm_start=False, class_weight=None, ccp_alpha=0.015, max_samples=.5)\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'criterion':['gini'],\n",
    "#     'max_depth': [4],\n",
    "#     'max_samples':[.5],\n",
    "#     'min_samples_split': [.0001],\n",
    "#     'min_samples_leaf':[1],\n",
    "#     'n_estimators': [400,600,800],\n",
    "#     'ccp_alpha':[.015]\n",
    "# }\n",
    "\n",
    "# grid_for = GridSearchCV(forest, param_grid, scoring='f1', cv=10, n_jobs=-1)\n",
    "grid_for.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:15.841105Z",
     "start_time": "2021-01-03T19:25:15.839059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# best_parameters = grid_for.best_params_\n",
    "\n",
    "# print('Grid Search found the following optimal parameters: ')\n",
    "# for param_name in sorted(best_parameters.keys()):\n",
    "#     print('%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:17.366365Z",
     "start_time": "2021-01-03T19:25:17.150713Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = grid_for.predict(X_test)\n",
    "y_pred_train = grid_for.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:18.602232Z",
     "start_time": "2021-01-03T19:25:18.563022Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy= metrics.accuracy_score(y_test, y_pred_class)\n",
    "recall= metrics.recall_score(y_test, y_pred_class)\n",
    "precision= metrics.precision_score(y_test, y_pred_class)\n",
    "f1= metrics.f1_score(y_test, y_pred_class)\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "fpr = 1 - tnr\n",
    "\n",
    "t_accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "t_recall = metrics.recall_score(y_train, y_pred_train)\n",
    "t_precision=metrics.precision_score(y_train, y_pred_train)\n",
    "t_f1=metrics.f1_score(y_train, y_pred_train)\n",
    "t_tnr = metrics.recall_score(y_train, y_pred_train, pos_label = 0)\n",
    "t_fpr = 1 - t_tnr\n",
    "\n",
    "accuracy= metrics.accuracy_score(y_test, y_pred_class)\n",
    "recall= metrics.recall_score(y_test, y_pred_class)\n",
    "precision= metrics.precision_score(y_test, y_pred_class)\n",
    "f1= metrics.f1_score(y_test, y_pred_class)\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "fpr = 1 - tnr\n",
    "\n",
    "t_accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "t_recall = metrics.recall_score(y_train, y_pred_train)\n",
    "t_precision=metrics.precision_score(y_train, y_pred_train)\n",
    "t_f1=metrics.f1_score(y_train, y_pred_train)\n",
    "t_tnr = metrics.recall_score(y_train, y_pred_train, pos_label = 0)\n",
    "t_fpr = 1 - t_tnr\n",
    "\n",
    "print('Testing Data')\n",
    "print('Positive likelihood ratio',recall/fpr)\n",
    "print('recall_score', recall)\n",
    "print('precision_score', precision)\n",
    "print('accuracy_score', accuracy)\n",
    "print('balanced accuracy_score', metrics.balanced_accuracy_score(y_test, y_pred_class))\n",
    "print('f1_score', f1)\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred_class))\n",
    "\n",
    "print('\\nTraining Data')\n",
    "print('Positive likelihood ratio',t_recall/t_fpr)\n",
    "print('recall_score', t_recall)\n",
    "print('precision_score', t_precision)\n",
    "print('accuracy_score', t_accuracy)\n",
    "print('f1_score', t_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:20.234752Z",
     "start_time": "2021-01-03T19:25:20.214928Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(data=[metrics.accuracy_score(y_test, y_pred_class), metrics.recall_score(y_test, y_pred_class),\n",
    "                   metrics.precision_score(y_test, y_pred_class), metrics.f1_score(y_test, y_pred_class)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'test_set'}),\n",
    "pd.DataFrame(data=[metrics.accuracy_score(y_train, y_pred_train), metrics.recall_score(y_train, y_pred_train),\n",
    "                   metrics.precision_score(y_train, y_pred_train), metrics.f1_score(y_train, y_pred_train)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'train_set'})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:24.529946Z",
     "start_time": "2021-01-03T19:25:24.333167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_class)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_for.classes_)\n",
    "plt.savefig(\"figures/Confusion_Matrix_forest\")\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix Forest Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:25:25.897858Z",
     "start_time": "2021-01-03T19:25:25.892136Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function used to plot feature importance greater than zero\n",
    "def plot_feature_importances(model, name=''):\n",
    "    #get feature importance\n",
    "    dic={}\n",
    "    for col,val in zip(X_train.columns, model.feature_importances_):\n",
    "        dic[col]=val\n",
    "    dic =dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
    "    #remove all zero values\n",
    "    rm=[]\n",
    "    for d,k in dic.items():\n",
    "        if k==0:\n",
    "            rm.append(d)\n",
    "    for i in rm:\n",
    "        dic.pop(i)\n",
    "    #graph importance\n",
    "    plt.figure(figsize=(40,40))\n",
    "    ax = sns.barplot(x=list(dic.values()), y=list(dic.keys()), palette=\"Blues_d\")\n",
    "    plt.title(\"Feature Importance \"+name+ \" Model\", fontsize=50)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.xlabel('Feature importance', fontsize=30)\n",
    "    plt.ylabel('Features', fontsize=30)\n",
    "    if name:\n",
    "        plt.savefig(\"figures/Feature_Importance_\"+name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T19:26:13.776288Z",
     "start_time": "2021-01-03T19:26:11.202989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(grid_for, 'Random_Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T20:01:21.591404Z",
     "start_time": "2021-01-03T20:01:21.585729Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(base_score=0.5, booster='gbtree', subsample=.6, colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1,\n",
    "              learning_rate=0.4, max_delta_step=0, max_depth=4, min_split_loss=1,\n",
    "              min_child_weight=1, missing=None, n_estimators=700, n_jobs=-1,\n",
    "              nthread=None, objective='binary:logistic', random_state=22,\n",
    "              reg_alpha=3, reg_lambda=125, scale_pos_weight=1, seed=None,\n",
    "              silent=None, verbosity=1)\n",
    "\n",
    "# Grid Search found the following optimal parameters: \n",
    "# learning_rate: 0.4\n",
    "# max_delta_step: 0\n",
    "# max_depth: 4\n",
    "# min_child_weight: 1\n",
    "# min_split_loss: 1\n",
    "# n_estimators: 700\n",
    "# reg_alpha: 3\n",
    "# reg_lambda: 125\n",
    "# subsample: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T20:01:23.764030Z",
     "start_time": "2021-01-03T20:01:23.263158Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T20:01:25.584185Z",
     "start_time": "2021-01-03T20:01:25.571226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = xgb.predict(X_test)\n",
    "y_pred_train = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:57:22.006285Z",
     "start_time": "2021-01-02T00:57:21.967829Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy= metrics.accuracy_score(y_test, y_pred_class)\n",
    "recall= metrics.recall_score(y_test, y_pred_class)\n",
    "precision= metrics.precision_score(y_test, y_pred_class)\n",
    "f1= metrics.f1_score(y_test, y_pred_class)\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "fpr = 1 - tnr\n",
    "\n",
    "t_accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "t_recall = metrics.recall_score(y_train, y_pred_train)\n",
    "t_precision=metrics.precision_score(y_train, y_pred_train)\n",
    "t_f1=metrics.f1_score(y_train, y_pred_train)\n",
    "t_tnr = metrics.recall_score(y_train, y_pred_train, pos_label = 0)\n",
    "t_fpr = 1 - t_tnr\n",
    "\n",
    "accuracy= metrics.accuracy_score(y_test, y_pred_class)\n",
    "recall= metrics.recall_score(y_test, y_pred_class)\n",
    "precision= metrics.precision_score(y_test, y_pred_class)\n",
    "f1= metrics.f1_score(y_test, y_pred_class)\n",
    "tnr = metrics.recall_score(y_test, y_pred_class, pos_label = 0)\n",
    "fpr = 1 - tnr\n",
    "\n",
    "t_accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "t_recall = metrics.recall_score(y_train, y_pred_train)\n",
    "t_precision=metrics.precision_score(y_train, y_pred_train)\n",
    "t_f1=metrics.f1_score(y_train, y_pred_train)\n",
    "t_tnr = metrics.recall_score(y_train, y_pred_train, pos_label = 0)\n",
    "t_fpr = 1 - t_tnr\n",
    "\n",
    "print('Testing Data')\n",
    "print('Positive likelihood ratio',recall/fpr)\n",
    "print('recall_score', recall)\n",
    "print('precision_score', precision)\n",
    "print('accuracy_score', accuracy)\n",
    "print('balanced accuracy_score', metrics.balanced_accuracy_score(y_test, y_pred_class))\n",
    "print('f1_score', f1)\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred_class))\n",
    "\n",
    "print('\\nTraining Data')\n",
    "print('Positive likelihood ratio',t_recall/t_fpr)\n",
    "print('recall_score', t_recall)\n",
    "print('precision_score', t_precision)\n",
    "print('accuracy_score', t_accuracy)\n",
    "print('f1_score', t_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:57:33.548472Z",
     "start_time": "2021-01-02T00:57:33.525585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(data=[metrics.accuracy_score(y_test, y_pred_class), metrics.recall_score(y_test, y_pred_class),\n",
    "                   metrics.precision_score(y_test, y_pred_class), metrics.f1_score(y_test, y_pred_class)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'test_set'}),\n",
    "pd.DataFrame(data=[metrics.accuracy_score(y_train, y_pred_train), metrics.recall_score(y_train, y_pred_train),\n",
    "                   metrics.precision_score(y_train, y_pred_train), metrics.f1_score(y_train, y_pred_train)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"F1\"]).rename(columns={0:'train_set'})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T00:57:35.523586Z",
     "start_time": "2021-01-02T00:57:35.311573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred_class)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb.classes_)\n",
    "plt.savefig(\"figures/Confusion_Matrix_xgb\")\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix XGB Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T18:58:07.429448Z",
     "start_time": "2021-01-03T18:58:06.631873Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(xgb, 'xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
